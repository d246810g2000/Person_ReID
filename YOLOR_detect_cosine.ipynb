{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a66820b",
   "metadata": {
    "id": "UL_9sBkuYsBz"
   },
   "source": [
    "# YOLOR + ReID 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc8cc767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('PyTorch_YOLOv4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d061e84",
   "metadata": {
    "id": "IeXiY6goZNjE"
   },
   "source": [
    "## 匯入所需套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edcd1a9e",
   "metadata": {
    "id": "a91de30c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.google_utils import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import (\n",
    "    check_img_size, non_max_suppression, apply_classifier, scale_coords, xyxy2xywh, strip_optimizer)\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized\n",
    "\n",
    "from models.models import *\n",
    "from utils.datasets import *\n",
    "from utils.general import *\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f24fdd",
   "metadata": {
    "id": "811cd6d5"
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f02da5",
   "metadata": {
    "id": "89uLk_rVZsh3"
   },
   "source": [
    "## 參數設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c366f957",
   "metadata": {
    "id": "5a4cafe9"
   },
   "outputs": [],
   "source": [
    "weights = 'wandb/latest-run/files/best.pt'\n",
    "source = 'person_reid_datasets/test/'\n",
    "sub = 'person_reid_datasets/sample_submission.csv'\n",
    "out = 'inference/output'\n",
    "cfg = 'yolor/cfg/yolor_csp.cfg'\n",
    "data = 'yolor/data/pedestrian.yaml'\n",
    "imgsz = 640\n",
    "conf_thres = 0.25\n",
    "iou_thres = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d12d2962",
   "metadata": {
    "id": "FjS_vnLDZxBX"
   },
   "outputs": [],
   "source": [
    "# 創建資料夾\n",
    "if os.path.exists(out):\n",
    "    shutil.rmtree(out)  # delete output folder\n",
    "os.makedirs(out)  # make new output folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8c2d97",
   "metadata": {
    "id": "ULXI0iSRZaJD"
   },
   "source": [
    "## 將訓練好的偵測模型權重和 ReID 模型權重讀入到各自的模型中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4032d4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26c6a5ae",
    "outputId": "134ef9a3-30f9-465f-c1d5-df0411900942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unrecognized Layer Type: implicit_add\n",
      "Warning: Unrecognized Layer Type: implicit_add\n",
      "Warning: Unrecognized Layer Type: implicit_add\n",
      "Warning: Unrecognized Layer Type: implicit_mul\n",
      "Warning: Unrecognized Layer Type: implicit_mul\n",
      "Warning: Unrecognized Layer Type: implicit_mul\n",
      "Warning: Unrecognized Layer Type: shift_channels\n",
      "Warning: Unrecognized Layer Type: control_channels\n",
      "WARNING: smart bias initialization failure.\n",
      "Warning: Unrecognized Layer Type: shift_channels\n",
      "Warning: Unrecognized Layer Type: control_channels\n",
      "WARNING: smart bias initialization failure.\n",
      "Warning: Unrecognized Layer Type: shift_channels\n",
      "Warning: Unrecognized Layer Type: control_channels\n",
      "WARNING: smart bias initialization failure.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Darknet:\n\tMissing key(s) in state_dict: \"module_list.3.Conv2d.weight\", \"module_list.3.BatchNorm2d.weight\", \"module_list.3.BatchNorm2d.bias\", \"module_list.3.BatchNorm2d.running_mean\", \"module_list.3.BatchNorm2d.running_var\", \"module_list.9.Conv2d.weight\", \"module_list.9.BatchNorm2d.weight\", \"module_list.9.BatchNorm2d.bias\", \"module_list.9.BatchNorm2d.running_mean\", \"module_list.9.BatchNorm2d.running_var\", \"module_list.13.Conv2d.weight\", \"module_list.13.BatchNorm2d.weight\", \"module_list.13.BatchNorm2d.bias\", \"module_list.13.BatchNorm2d.running_mean\", \"module_list.13.BatchNorm2d.running_var\", \"module_list.17.Conv2d.weight\", \"module_list.17.BatchNorm2d.weight\", \"module_list.17.BatchNorm2d.bias\", \"module_list.17.BatchNorm2d.running_mean\", \"module_list.17.BatchNorm2d.running_var\", \"module_list.22.Conv2d.weight\", \"module_list.22.BatchNorm2d.weight\", \"module_list.22.BatchNorm2d.bias\", \"module_list.22.BatchNorm2d.running_mean\", \"module_list.22.BatchNorm2d.running_var\", \"module_list.26.Conv2d.weight\", \"module_list.26.BatchNorm2d.weight\", \"module_list.26.BatchNorm2d.bias\", \"module_list.26.BatchNorm2d.running_mean\", \"module_list.26.BatchNorm2d.running_var\", \"module_list.48.Conv2d.weight\", \"module_list.48.BatchNorm2d.weight\", \"module_list.48.BatchNorm2d.bias\", \"module_list.48.BatchNorm2d.running_mean\", \"module_list.48.BatchNorm2d.running_var\", \"module_list.53.Conv2d.weight\", \"module_list.53.BatchNorm2d.weight\", \"module_list.53.BatchNorm2d.bias\", \"module_list.53.BatchNorm2d.running_mean\", \"module_list.53.BatchNorm2d.running_var\", \"module_list.57.Conv2d.weight\", \"module_list.57.BatchNorm2d.weight\", \"module_list.57.BatchNorm2d.bias\", \"module_list.57.BatchNorm2d.running_mean\", \"module_list.57.BatchNorm2d.running_var\", \"module_list.79.Conv2d.weight\", \"module_list.79.BatchNorm2d.weight\", \"module_list.79.BatchNorm2d.bias\", \"module_list.79.BatchNorm2d.running_mean\", \"module_list.79.BatchNorm2d.running_var\", \"module_list.84.Conv2d.weight\", \"module_list.84.BatchNorm2d.weight\", \"module_list.84.BatchNorm2d.bias\", \"module_list.84.BatchNorm2d.running_mean\", \"module_list.84.BatchNorm2d.running_var\", \"module_list.88.Conv2d.weight\", \"module_list.88.BatchNorm2d.weight\", \"module_list.88.BatchNorm2d.bias\", \"module_list.88.BatchNorm2d.running_mean\", \"module_list.88.BatchNorm2d.running_var\", \"module_list.98.Conv2d.weight\", \"module_list.98.BatchNorm2d.weight\", \"module_list.98.BatchNorm2d.bias\", \"module_list.98.BatchNorm2d.running_mean\", \"module_list.98.BatchNorm2d.running_var\", \"module_list.101.Conv2d.weight\", \"module_list.101.BatchNorm2d.weight\", \"module_list.101.BatchNorm2d.bias\", \"module_list.101.BatchNorm2d.running_mean\", \"module_list.101.BatchNorm2d.running_var\", \"module_list.103.Conv2d.weight\", \"module_list.103.BatchNorm2d.weight\", \"module_list.103.BatchNorm2d.bias\", \"module_list.103.BatchNorm2d.running_mean\", \"module_list.103.BatchNorm2d.running_var\", \"module_list.110.Conv2d.weight\", \"module_list.110.BatchNorm2d.weight\", \"module_list.110.BatchNorm2d.bias\", \"module_list.110.BatchNorm2d.running_mean\", \"module_list.110.BatchNorm2d.running_var\", \"module_list.111.Conv2d.weight\", \"module_list.111.BatchNorm2d.weight\", \"module_list.111.BatchNorm2d.bias\", \"module_list.111.BatchNorm2d.running_mean\", \"module_list.111.BatchNorm2d.running_var\", \"module_list.113.Conv2d.weight\", \"module_list.113.BatchNorm2d.weight\", \"module_list.113.BatchNorm2d.bias\", \"module_list.113.BatchNorm2d.running_mean\", \"module_list.113.BatchNorm2d.running_var\", \"module_list.119.Conv2d.weight\", \"module_list.119.BatchNorm2d.weight\", \"module_list.119.BatchNorm2d.bias\", \"module_list.119.BatchNorm2d.running_mean\", \"module_list.119.BatchNorm2d.running_var\", \"module_list.128.Conv2d.weight\", \"module_list.128.BatchNorm2d.weight\", \"module_list.128.BatchNorm2d.bias\", \"module_list.128.BatchNorm2d.running_mean\", \"module_list.128.BatchNorm2d.running_var\", \"module_list.131.Conv2d.weight\", \"module_list.131.BatchNorm2d.weight\", \"module_list.131.BatchNorm2d.bias\", \"module_list.131.BatchNorm2d.running_mean\", \"module_list.131.BatchNorm2d.running_var\", \"module_list.138.BatchNorm2d.weight\", \"module_list.138.BatchNorm2d.bias\", \"module_list.138.BatchNorm2d.running_mean\", \"module_list.138.BatchNorm2d.running_var\", \"module_list.139.Conv2d.weight\", \"module_list.139.BatchNorm2d.weight\", \"module_list.139.BatchNorm2d.bias\", \"module_list.139.BatchNorm2d.running_mean\", \"module_list.139.BatchNorm2d.running_var\", \"module_list.142.Conv2d.weight\", \"module_list.142.BatchNorm2d.weight\", \"module_list.142.BatchNorm2d.bias\", \"module_list.142.BatchNorm2d.running_mean\", \"module_list.142.BatchNorm2d.running_var\", \"module_list.149.BatchNorm2d.weight\", \"module_list.149.BatchNorm2d.bias\", \"module_list.149.BatchNorm2d.running_mean\", \"module_list.149.BatchNorm2d.running_var\", \"module_list.150.Conv2d.weight\", \"module_list.150.BatchNorm2d.weight\", \"module_list.150.BatchNorm2d.bias\", \"module_list.150.BatchNorm2d.running_mean\", \"module_list.150.BatchNorm2d.running_var\", \"module_list.153.Conv2d.weight\", \"module_list.153.BatchNorm2d.weight\", \"module_list.153.BatchNorm2d.bias\", \"module_list.153.BatchNorm2d.running_mean\", \"module_list.153.BatchNorm2d.running_var\", \"module_list.160.BatchNorm2d.weight\", \"module_list.160.BatchNorm2d.bias\", \"module_list.160.BatchNorm2d.running_mean\", \"module_list.160.BatchNorm2d.running_var\", \"module_list.161.Conv2d.weight\", \"module_list.161.BatchNorm2d.weight\", \"module_list.161.BatchNorm2d.bias\", \"module_list.161.BatchNorm2d.running_mean\", \"module_list.161.BatchNorm2d.running_var\", \"module_list.163.Conv2d.weight\", \"module_list.163.BatchNorm2d.weight\", \"module_list.163.BatchNorm2d.bias\", \"module_list.163.BatchNorm2d.running_mean\", \"module_list.163.BatchNorm2d.running_var\", \"module_list.171.Conv2d.weight\", \"module_list.171.BatchNorm2d.weight\", \"module_list.171.BatchNorm2d.bias\", \"module_list.171.BatchNorm2d.running_mean\", \"module_list.171.BatchNorm2d.running_var\", \"module_list.173.Conv2d.weight\", \"module_list.173.Conv2d.bias\", \"module_list.177.Conv2d.weight\", \"module_list.177.BatchNorm2d.weight\", \"module_list.177.BatchNorm2d.bias\", \"module_list.177.BatchNorm2d.running_mean\", \"module_list.177.BatchNorm2d.running_var\", \"module_list.179.Conv2d.weight\", \"module_list.179.Conv2d.bias\", \"module_list.183.Conv2d.weight\", \"module_list.183.BatchNorm2d.weight\", \"module_list.183.BatchNorm2d.bias\", \"module_list.183.BatchNorm2d.running_mean\", \"module_list.183.BatchNorm2d.running_var\", \"module_list.185.Conv2d.weight\", \"module_list.185.Conv2d.bias\". \n\tUnexpected key(s) in state_dict: \"module_list.4.Conv2d.weight\", \"module_list.4.BatchNorm2d.weight\", \"module_list.4.BatchNorm2d.bias\", \"module_list.4.BatchNorm2d.running_mean\", \"module_list.4.BatchNorm2d.running_var\", \"module_list.4.BatchNorm2d.num_batches_tracked\", \"module_list.11.Conv2d.weight\", \"module_list.11.BatchNorm2d.weight\", \"module_list.11.BatchNorm2d.bias\", \"module_list.11.BatchNorm2d.running_mean\", \"module_list.11.BatchNorm2d.running_var\", \"module_list.11.BatchNorm2d.num_batches_tracked\", \"module_list.14.Conv2d.weight\", \"module_list.14.BatchNorm2d.weight\", \"module_list.14.BatchNorm2d.bias\", \"module_list.14.BatchNorm2d.running_mean\", \"module_list.14.BatchNorm2d.running_var\", \"module_list.14.BatchNorm2d.num_batches_tracked\", \"module_list.16.Conv2d.weight\", \"module_list.16.BatchNorm2d.weight\", \"module_list.16.BatchNorm2d.bias\", \"module_list.16.BatchNorm2d.running_mean\", \"module_list.16.BatchNorm2d.running_var\", \"module_list.16.BatchNorm2d.num_batches_tracked\", \"module_list.24.Conv2d.weight\", \"module_list.24.BatchNorm2d.weight\", \"module_list.24.BatchNorm2d.bias\", \"module_list.24.BatchNorm2d.running_mean\", \"module_list.24.BatchNorm2d.running_var\", \"module_list.24.BatchNorm2d.num_batches_tracked\", \"module_list.27.Conv2d.weight\", \"module_list.27.BatchNorm2d.weight\", \"module_list.27.BatchNorm2d.bias\", \"module_list.27.BatchNorm2d.running_mean\", \"module_list.27.BatchNorm2d.running_var\", \"module_list.27.BatchNorm2d.num_batches_tracked\", \"module_list.47.Conv2d.weight\", \"module_list.47.BatchNorm2d.weight\", \"module_list.47.BatchNorm2d.bias\", \"module_list.47.BatchNorm2d.running_mean\", \"module_list.47.BatchNorm2d.running_var\", \"module_list.47.BatchNorm2d.num_batches_tracked\", \"module_list.55.Conv2d.weight\", \"module_list.55.BatchNorm2d.weight\", \"module_list.55.BatchNorm2d.bias\", \"module_list.55.BatchNorm2d.running_mean\", \"module_list.55.BatchNorm2d.running_var\", \"module_list.55.BatchNorm2d.num_batches_tracked\", \"module_list.58.Conv2d.weight\", \"module_list.58.BatchNorm2d.weight\", \"module_list.58.BatchNorm2d.bias\", \"module_list.58.BatchNorm2d.running_mean\", \"module_list.58.BatchNorm2d.running_var\", \"module_list.58.BatchNorm2d.num_batches_tracked\", \"module_list.78.Conv2d.weight\", \"module_list.78.BatchNorm2d.weight\", \"module_list.78.BatchNorm2d.bias\", \"module_list.78.BatchNorm2d.running_mean\", \"module_list.78.BatchNorm2d.running_var\", \"module_list.78.BatchNorm2d.num_batches_tracked\", \"module_list.86.Conv2d.weight\", \"module_list.86.BatchNorm2d.weight\", \"module_list.86.BatchNorm2d.bias\", \"module_list.86.BatchNorm2d.running_mean\", \"module_list.86.BatchNorm2d.running_var\", \"module_list.86.BatchNorm2d.num_batches_tracked\", \"module_list.89.Conv2d.weight\", \"module_list.89.BatchNorm2d.weight\", \"module_list.89.BatchNorm2d.bias\", \"module_list.89.BatchNorm2d.running_mean\", \"module_list.89.BatchNorm2d.running_var\", \"module_list.89.BatchNorm2d.num_batches_tracked\", \"module_list.97.Conv2d.weight\", \"module_list.97.BatchNorm2d.weight\", \"module_list.97.BatchNorm2d.bias\", \"module_list.97.BatchNorm2d.running_mean\", \"module_list.97.BatchNorm2d.running_var\", \"module_list.97.BatchNorm2d.num_batches_tracked\", \"module_list.100.Conv2d.weight\", \"module_list.100.BatchNorm2d.weight\", \"module_list.100.BatchNorm2d.bias\", \"module_list.100.BatchNorm2d.running_mean\", \"module_list.100.BatchNorm2d.running_var\", \"module_list.100.BatchNorm2d.num_batches_tracked\", \"module_list.104.Conv2d.weight\", \"module_list.104.BatchNorm2d.weight\", \"module_list.104.BatchNorm2d.bias\", \"module_list.104.BatchNorm2d.running_mean\", \"module_list.104.BatchNorm2d.running_var\", \"module_list.104.BatchNorm2d.num_batches_tracked\", \"module_list.105.Conv2d.weight\", \"module_list.105.BatchNorm2d.weight\", \"module_list.105.BatchNorm2d.bias\", \"module_list.105.BatchNorm2d.running_mean\", \"module_list.105.BatchNorm2d.running_var\", \"module_list.105.BatchNorm2d.num_batches_tracked\", \"module_list.106.Conv2d.weight\", \"module_list.106.BatchNorm2d.weight\", \"module_list.106.BatchNorm2d.bias\", \"module_list.106.BatchNorm2d.running_mean\", \"module_list.106.BatchNorm2d.running_var\", \"module_list.106.BatchNorm2d.num_batches_tracked\", \"module_list.107.Conv2d.weight\", \"module_list.107.BatchNorm2d.weight\", \"module_list.107.BatchNorm2d.bias\", \"module_list.107.BatchNorm2d.running_mean\", \"module_list.107.BatchNorm2d.running_var\", \"module_list.107.BatchNorm2d.num_batches_tracked\", \"module_list.115.Conv2d.weight\", \"module_list.115.BatchNorm2d.weight\", \"module_list.115.BatchNorm2d.bias\", \"module_list.115.BatchNorm2d.running_mean\", \"module_list.115.BatchNorm2d.running_var\", \"module_list.115.BatchNorm2d.num_batches_tracked\", \"module_list.116.Conv2d.weight\", \"module_list.116.BatchNorm2d.weight\", \"module_list.116.BatchNorm2d.bias\", \"module_list.116.BatchNorm2d.running_mean\", \"module_list.116.BatchNorm2d.running_var\", \"module_list.116.BatchNorm2d.num_batches_tracked\", \"module_list.126.Conv2d.weight\", \"module_list.126.BatchNorm2d.weight\", \"module_list.126.BatchNorm2d.bias\", \"module_list.126.BatchNorm2d.running_mean\", \"module_list.126.BatchNorm2d.running_var\", \"module_list.126.BatchNorm2d.num_batches_tracked\", \"module_list.130.Conv2d.weight\", \"module_list.130.BatchNorm2d.weight\", \"module_list.130.BatchNorm2d.bias\", \"module_list.130.BatchNorm2d.running_mean\", \"module_list.130.BatchNorm2d.running_var\", \"module_list.130.BatchNorm2d.num_batches_tracked\", \"module_list.132.Conv2d.weight\", \"module_list.132.BatchNorm2d.weight\", \"module_list.132.BatchNorm2d.bias\", \"module_list.132.BatchNorm2d.running_mean\", \"module_list.132.BatchNorm2d.running_var\", \"module_list.132.BatchNorm2d.num_batches_tracked\", \"module_list.135.Conv2d.weight\", \"module_list.135.BatchNorm2d.weight\", \"module_list.135.BatchNorm2d.bias\", \"module_list.135.BatchNorm2d.running_mean\", \"module_list.135.BatchNorm2d.running_var\", \"module_list.135.BatchNorm2d.num_batches_tracked\", \"module_list.138.Conv2d.bias\", \"module_list.143.Conv2d.weight\", \"module_list.143.BatchNorm2d.weight\", \"module_list.143.BatchNorm2d.bias\", \"module_list.143.BatchNorm2d.running_mean\", \"module_list.143.BatchNorm2d.running_var\", \"module_list.143.BatchNorm2d.num_batches_tracked\", \"module_list.146.Conv2d.weight\", \"module_list.146.BatchNorm2d.weight\", \"module_list.146.BatchNorm2d.bias\", \"module_list.146.BatchNorm2d.running_mean\", \"module_list.146.BatchNorm2d.running_var\", \"module_list.146.BatchNorm2d.num_batches_tracked\", \"module_list.149.Conv2d.bias\", \"module_list.154.Conv2d.weight\", \"module_list.154.BatchNorm2d.weight\", \"module_list.154.BatchNorm2d.bias\", \"module_list.154.BatchNorm2d.running_mean\", \"module_list.154.BatchNorm2d.running_var\", \"module_list.154.BatchNorm2d.num_batches_tracked\", \"module_list.157.Conv2d.weight\", \"module_list.157.BatchNorm2d.weight\", \"module_list.157.BatchNorm2d.bias\", \"module_list.157.BatchNorm2d.running_mean\", \"module_list.157.BatchNorm2d.running_var\", \"module_list.157.BatchNorm2d.num_batches_tracked\", \"module_list.160.Conv2d.bias\". \n\tsize mismatch for module_list.2.Conv2d.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 64, 1, 1]).\n\tsize mismatch for module_list.2.BatchNorm2d.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module_list.2.BatchNorm2d.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module_list.2.BatchNorm2d.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module_list.2.BatchNorm2d.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module_list.5.Conv2d.weight: copying a param with shape torch.Size([32, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for module_list.5.BatchNorm2d.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.5.BatchNorm2d.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.5.BatchNorm2d.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.5.BatchNorm2d.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.6.Conv2d.weight: copying a param with shape torch.Size([64, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n\tsize mismatch for module_list.8.Conv2d.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n\tsize mismatch for module_list.10.Conv2d.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for module_list.12.Conv2d.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for module_list.18.Conv2d.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n\tsize mismatch for module_list.18.BatchNorm2d.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.18.BatchNorm2d.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.18.BatchNorm2d.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.18.BatchNorm2d.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.19.Conv2d.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for module_list.19.BatchNorm2d.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.19.BatchNorm2d.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.19.BatchNorm2d.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.19.BatchNorm2d.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.21.Conv2d.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for module_list.21.BatchNorm2d.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.21.BatchNorm2d.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.21.BatchNorm2d.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.21.BatchNorm2d.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.23.Conv2d.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for module_list.25.Conv2d.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n\tsize mismatch for module_list.49.Conv2d.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).\n\tsize mismatch for module_list.49.BatchNorm2d.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.49.BatchNorm2d.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.49.BatchNorm2d.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.49.BatchNorm2d.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.50.Conv2d.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.50.BatchNorm2d.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.50.BatchNorm2d.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.50.BatchNorm2d.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.50.BatchNorm2d.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.52.Conv2d.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.52.BatchNorm2d.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.52.BatchNorm2d.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.52.BatchNorm2d.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.52.BatchNorm2d.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.54.Conv2d.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for module_list.56.Conv2d.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module_list.80.Conv2d.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3, 3]).\n\tsize mismatch for module_list.80.BatchNorm2d.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.80.BatchNorm2d.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.80.BatchNorm2d.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.80.BatchNorm2d.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.81.Conv2d.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for module_list.81.BatchNorm2d.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.81.BatchNorm2d.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.81.BatchNorm2d.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.81.BatchNorm2d.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.83.Conv2d.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for module_list.83.BatchNorm2d.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.83.BatchNorm2d.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.83.BatchNorm2d.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.83.BatchNorm2d.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.85.Conv2d.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for module_list.87.Conv2d.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n\tsize mismatch for module_list.99.Conv2d.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for module_list.102.Conv2d.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for module_list.114.Conv2d.weight: copying a param with shape torch.Size([512, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.114.BatchNorm2d.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.114.BatchNorm2d.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.114.BatchNorm2d.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.114.BatchNorm2d.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.120.Conv2d.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module_list.122.Conv2d.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module_list.123.Conv2d.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for module_list.123.BatchNorm2d.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.123.BatchNorm2d.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.123.BatchNorm2d.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.123.BatchNorm2d.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.124.Conv2d.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module_list.125.Conv2d.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for module_list.125.BatchNorm2d.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.125.BatchNorm2d.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.125.BatchNorm2d.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.125.BatchNorm2d.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.127.Conv2d.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.127.BatchNorm2d.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.127.BatchNorm2d.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.127.BatchNorm2d.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.127.BatchNorm2d.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.133.Conv2d.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for module_list.133.BatchNorm2d.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.133.BatchNorm2d.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.133.BatchNorm2d.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.133.BatchNorm2d.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.134.Conv2d.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n\tsize mismatch for module_list.136.Conv2d.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n\tsize mismatch for module_list.137.Conv2d.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for module_list.137.BatchNorm2d.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.137.BatchNorm2d.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.137.BatchNorm2d.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.137.BatchNorm2d.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.138.Conv2d.weight: copying a param with shape torch.Size([18, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n\tsize mismatch for module_list.141.Conv2d.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for module_list.141.BatchNorm2d.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.141.BatchNorm2d.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.141.BatchNorm2d.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.141.BatchNorm2d.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.144.Conv2d.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.144.BatchNorm2d.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.144.BatchNorm2d.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.144.BatchNorm2d.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.144.BatchNorm2d.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.145.Conv2d.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module_list.147.Conv2d.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module_list.148.Conv2d.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for module_list.148.BatchNorm2d.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.148.BatchNorm2d.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.148.BatchNorm2d.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.148.BatchNorm2d.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.149.Conv2d.weight: copying a param with shape torch.Size([18, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module_list.152.Conv2d.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.152.BatchNorm2d.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.152.BatchNorm2d.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.152.BatchNorm2d.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.152.BatchNorm2d.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.155.Conv2d.weight: copying a param with shape torch.Size([1024, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for module_list.155.BatchNorm2d.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.155.BatchNorm2d.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.155.BatchNorm2d.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.155.BatchNorm2d.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.156.Conv2d.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n\tsize mismatch for module_list.158.Conv2d.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n\tsize mismatch for module_list.159.Conv2d.weight: copying a param with shape torch.Size([1024, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for module_list.159.BatchNorm2d.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.159.BatchNorm2d.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.159.BatchNorm2d.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.159.BatchNorm2d.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.160.Conv2d.weight: copying a param with shape torch.Size([18, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7111/2806537826.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDarknet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1407\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Darknet:\n\tMissing key(s) in state_dict: \"module_list.3.Conv2d.weight\", \"module_list.3.BatchNorm2d.weight\", \"module_list.3.BatchNorm2d.bias\", \"module_list.3.BatchNorm2d.running_mean\", \"module_list.3.BatchNorm2d.running_var\", \"module_list.9.Conv2d.weight\", \"module_list.9.BatchNorm2d.weight\", \"module_list.9.BatchNorm2d.bias\", \"module_list.9.BatchNorm2d.running_mean\", \"module_list.9.BatchNorm2d.running_var\", \"module_list.13.Conv2d.weight\", \"module_list.13.BatchNorm2d.weight\", \"module_list.13.BatchNorm2d.bias\", \"module_list.13.BatchNorm2d.running_mean\", \"module_list.13.BatchNorm2d.running_var\", \"module_list.17.Conv2d.weight\", \"module_list.17.BatchNorm2d.weight\", \"module_list.17.BatchNorm2d.bias\", \"module_list.17.BatchNorm2d.running_mean\", \"module_list.17.BatchNorm2d.running_var\", \"module_list.22.Conv2d.weight\", \"module_list.22.BatchNorm2d.weight\", \"module_list.22.BatchNorm2d.bias\", \"module_list.22.BatchNorm2d.running_mean\", \"module_list.22.BatchNorm2d.running_var\", \"module_list.26.Conv2d.weight\", \"module_list.26.BatchNorm2d.weight\", \"module_list.26.BatchNorm2d.bias\", \"module_list.26.BatchNorm2d.running_mean\", \"module_list.26.BatchNorm2d.running_var\", \"module_list.48.Conv2d.weight\", \"module_list.48.BatchNorm2d.weight\", \"module_list.48.BatchNorm2d.bias\", \"module_list.48.BatchNorm2d.running_mean\", \"module_list.48.BatchNorm2d.running_var\", \"module_list.53.Conv2d.weight\", \"module_list.53.BatchNorm2d.weight\", \"module_list.53.BatchNorm2d.bias\", \"module_list.53.BatchNorm2d.running_mean\", \"module_list.53.BatchNorm2d.running_var\", \"module_list.57.Conv2d.weight\", \"module_list.57.BatchNorm2d.weight\", \"module_list.57.BatchNorm2d.bias\", \"module_list.57.BatchNorm2d.running_mean\", \"module_list.57.BatchNorm2d.running_var\", \"module_list.79.Conv2d.weight\", \"module_list.79.BatchNorm2d.weight\", \"module_list.79.BatchNorm2d.bias\", \"module_list.79.BatchNorm2d.running_mean\", \"module_list.79.BatchNorm2d.running_var\", \"module_list.84.Conv2d.weight\", \"module_list.84.BatchNorm2d.weight\", \"module_list.84.BatchNorm2d.bias\", \"module_list.84.BatchNorm2d.running_mean\", \"module_list.84.BatchNorm2d.running_var\", \"module_list.88.Conv2d.weight\", \"module_list.88.BatchNorm2d.weight\", \"module_list.88.BatchNorm2d.bias\", \"module_list.88.BatchNorm2d.running_mean\", \"module_list.88.BatchNorm2d.running_var\", \"module_list.98.Conv2d.weight\", \"module_list.98.BatchNorm2d.weight\", \"module_list.98.BatchNorm2d.bias\", \"module_list.98.BatchNorm2d.running_mean\", \"module_list.98.BatchNorm2d.running_var\", \"module_list.101.Conv2d.weight\", \"module_list.101.BatchNorm2d.weight\", \"module_list.101.BatchNorm2d.bias\", \"module_list.101.BatchNorm2d.running_mean\", \"module_list.101.BatchNorm2d.running_var\", \"module_list.103.Conv2d.weight\", \"module_list.103.BatchNorm2d.weight\", \"module_list.103.BatchNorm2d.bias\", \"module_list.103.BatchNorm2d.running_mean\", \"module_list.103.BatchNorm2d.running_var\", \"module_list.110.Conv2d.weight\", \"module_list.110.BatchNorm2d.weight\", \"module_list.110.BatchNorm2d.bias\", \"module_list.110.BatchNorm2d.running_mean\", \"module_list.110.BatchNorm2d.running_var\", \"module_list.111.Conv2d.weight\", \"module_list.111.BatchNorm2d.weight\", \"module_list.111.BatchNorm2d.bias\", \"module_list.111.BatchNorm2d.running_mean\", \"module_list.111.BatchNorm2d.running_var\", \"module_list.113.Conv2d.weight\", \"module_list.113.BatchNorm2d.weight\", \"module_list.113.BatchNorm2d.bias\", \"module_list.113.BatchNorm2d.running_mean\", \"module_list.113.BatchNorm2d.running_var\", \"module_list.119.Conv2d.weight\", \"module_list.119.BatchNorm2d.weight\", \"module_list.119.BatchNorm2d.bias\", \"module_list.119.BatchNorm2d.running_mean\", \"module_list.119.BatchNorm2d.running_var\", \"module_list.128.Conv2d.weight\", \"module_list.128.BatchNorm2d.weight\", \"module_list.128.BatchNorm2d.bias\", \"module_list.128.BatchNorm2d.running_mean\", \"module_list.128.BatchNorm2d.running_var\", \"module_list.131.Conv2d.weight\", \"module_list.131.BatchNorm2d.weight\", \"module_list.131.BatchNorm2d.bias\", \"module_list.131.BatchNorm2d.running_mean\", \"module_list.131.BatchNorm2d.running_var\", \"module_list.138.BatchNorm2d.weight\", \"module_list.138.BatchNorm2d.bias\", \"module_list.138.BatchNorm2d.running_mean\", \"module_list.138.BatchNorm2d.running_var\", \"module_list.139.Conv2d.weight\", \"module_list.139.BatchNorm2d.weight\", \"module_list.139.BatchNorm2d.bias\", \"module_list.139.BatchNorm2d.running_mean\", \"module_list.139.BatchNorm2d.running_var\", \"module_list.142.Conv2d.weight\", \"module_list.142.BatchNorm2d.weight\", \"module_list.142.BatchNorm2d.bias\", \"module_list.142.BatchNorm2d.running_mean\", \"module_list.142.BatchNorm2d.running_var\", \"module_list.149.BatchNorm2d.weight\", \"module_list.149.BatchNorm2d.bias\", \"module_list.149.BatchNorm2d.running_mean\", \"module_list.149.BatchNorm2d.running_var\", \"module_list.150.Conv2d.weight\", \"module_list.150.BatchNorm2d.weight\", \"module_list.150.BatchNorm2d.bias\", \"module_list.150.BatchNorm2d.running_mean\", \"module_list.150.BatchNorm2d.running_var\", \"module_list.153.Conv2d.weight\", \"module_list.153.BatchNorm2d.weight\", \"module_list.153.BatchNorm2d.bias\", \"module_list.153.BatchNorm2d.running_mean\", \"module_list.153.BatchNorm2d.running_var\", \"module_list.160.BatchNorm2d.weight\", \"module_list.160.BatchNorm2d.bias\", \"module_list.160.BatchNorm2d.running_mean\", \"module_list.160.BatchNorm2d.running_var\", \"module_list.161.Conv2d.weight\", \"module_list.161.BatchNorm2d.weight\", \"module_list.161.BatchNorm2d.bias\", \"module_list.161.BatchNorm2d.running_mean\", \"module_list.161.BatchNorm2d.running_var\", \"module_list.163.Conv2d.weight\", \"module_list.163.BatchNorm2d.weight\", \"module_list.163.BatchNorm2d.bias\", \"module_list.163.BatchNorm2d.running_mean\", \"module_list.163.BatchNorm2d.running_var\", \"module_list.171.Conv2d.weight\", \"module_list.171.BatchNorm2d.weight\", \"module_list.171.BatchNorm2d.bias\", \"module_list.171.BatchNorm2d.running_mean\", \"module_list.171.BatchNorm2d.running_var\", \"module_list.173.Conv2d.weight\", \"module_list.173.Conv2d.bias\", \"module_list.177.Conv2d.weight\", \"module_list.177.BatchNorm2d.weight\", \"module_list.177.BatchNorm2d.bias\", \"module_list.177.BatchNorm2d.running_mean\", \"module_list.177.BatchNorm2d.running_var\", \"module_list.179.Conv2d.weight\", \"module_list.179.Conv2d.bias\", \"module_list.183.Conv2d.weight\", \"module_list.183.BatchNorm2d.weight\", \"module_list.183.BatchNorm2d.bias\", \"module_list.183.BatchNorm2d.running_mean\", \"module_list.183.BatchNorm2d.running_var\", \"module_list.185.Conv2d.weight\", \"module_list.185.Conv2d.bias\". \n\tUnexpected key(s) in state_dict: \"module_list.4.Conv2d.weight\", \"module_list.4.BatchNorm2d.weight\", \"module_list.4.BatchNorm2d.bias\", \"module_list.4.BatchNorm2d.running_mean\", \"module_list.4.BatchNorm2d.running_var\", \"module_list.4.BatchNorm2d.num_batches_tracked\", \"module_list.11.Conv2d.weight\", \"module_list.11.BatchNorm2d.weight\", \"module_list.11.BatchNorm2d.bias\", \"module_list.11.BatchNorm2d.running_mean\", \"module_list.11.BatchNorm2d.running_var\", \"module_list.11.BatchNorm2d.num_batches_tracked\", \"module_list.14.Conv2d.weight\", \"module_list.14.BatchNorm2d.weight\", \"module_list.14.BatchNorm2d.bias\", \"module_list.14.BatchNorm2d.running_mean\", \"module_list.14.BatchNorm2d.running_var\", \"module_list.14.BatchNorm2d.num_batches_tracked\", \"module_list.16.Conv2d.weight\", \"module_list.16.BatchNorm2d.weight\", \"module_list.16.BatchNorm2d.bias\", \"module_list.16.BatchNorm2d.running_mean\", \"module_list.16.BatchNorm2d.running_var\", \"module_list.16.BatchNorm2d.num_batches_tracked\", \"module_list.24.Conv2d.weight\", \"module_list.24.BatchNorm2d.weight\", \"module_list.24.BatchNorm2d.bias\", \"module_list.24.BatchNorm2d.running_mean\", \"module_list.24.BatchNorm2d.running_var\", \"module_list.24.BatchNorm2d.num_batches_tracked\", \"module_list.27.Conv2d.weight\", \"module_list.27.BatchNorm2d.weight\", \"module_list.27.BatchNorm2d.bias\", \"module_list.27.BatchNorm2d.running_mean\", \"module_list.27.BatchNorm2d.running_var\", \"module_list.27.BatchNorm2d.num_batches_tracked\", \"module_list.47.Conv2d.weight\", \"module_list.47.BatchNorm2d.weight\", \"module_list.47.BatchNorm2d.bias\", \"module_list.47.BatchNorm2d.running_mean\", \"module_list.47.BatchNorm2d.running_var\", \"module_list.47.BatchNorm2d.num_batches_tracked\", \"module_list.55.Conv2d.weight\", \"module_list.55.BatchNorm2d.weight\", \"module_list.55.BatchNorm2d.bias\", \"module_list.55.BatchNorm2d.running_mean\", \"module_list.55.BatchNorm2d.running_var\", \"module_list.55.BatchNorm2d.num_batches_tracked\", \"module_list.58.Conv2d.weight\", \"module_list.58.BatchNorm2d.weight\", \"module_list.58.BatchNorm2d.bias\", \"module_list.58.BatchNorm2d.running_mean\", \"module_list.58.BatchNorm2d.running_var\", \"module_list.58.BatchNorm2d.num_batches_tracked\", \"module_list.78.Conv2d.weight\", \"module_list.78.BatchNorm2d.weight\", \"module_list.78.BatchNorm2d.bias\", \"module_list.78.BatchNorm2d.running_mean\", \"module_list.78.BatchNorm2d.running_var\", \"module_list.78.BatchNorm2d.num_batches_tracked\", \"module_list.86.Conv2d.weight\", \"module_list.86.BatchNorm2d.weight\", \"module_list.86.BatchNorm2d.bias\", \"module_list.86.BatchNorm2d.running_mean\", \"module_list.86.BatchNorm2d.running_var\", \"module_list.86.BatchNorm2d.num_batches_tracked\", \"module_list.89.Conv2d.weight\", \"module_list.89.BatchNorm2d.weight\", \"module_list.89.BatchNorm2d.bias\", \"module_list.89.BatchNorm2d.running_mean\", \"module_list.89.BatchNorm2d.running_var\", \"module_list.89.BatchNorm2d.num_batches_tracked\", \"module_list.97.Conv2d.weight\", \"module_list.97.BatchNorm2d.weight\", \"module_list.97.BatchNorm2d.bias\", \"module_list.97.BatchNorm2d.running_mean\", \"module_list.97.BatchNorm2d.running_var\", \"module_list.97.BatchNorm2d.num_batches_tracked\", \"module_list.100.Conv2d.weight\", \"module_list.100.BatchNorm2d.weight\", \"module_list.100.BatchNorm2d.bias\", \"module_list.100.BatchNorm2d.running_mean\", \"module_list.100.BatchNorm2d.running_var\", \"module_list.100.BatchNorm2d.num_batches_tracked\", \"module_list.104.Conv2d.weight\", \"module_list.104.BatchNorm2d.weight\", \"module_list.104.BatchNorm2d.bias\", \"module_list.104.BatchNorm2d.running_mean\", \"module_list.104.BatchNorm2d.running_var\", \"module_list.104.BatchNorm2d.num_batches_tracked\", \"module_list.105.Conv2d.weight\", \"module_list.105.BatchNorm2d.weight\", \"module_list.105.BatchNorm2d.bias\", \"module_list.105.BatchNorm2d.running_mean\", \"module_list.105.BatchNorm2d.running_var\", \"module_list.105.BatchNorm2d.num_batches_tracked\", \"module_list.106.Conv2d.weight\", \"module_list.106.BatchNorm2d.weight\", \"module_list.106.BatchNorm2d.bias\", \"module_list.106.BatchNorm2d.running_mean\", \"module_list.106.BatchNorm2d.running_var\", \"module_list.106.BatchNorm2d.num_batches_tracked\", \"module_list.107.Conv2d.weight\", \"module_list.107.BatchNorm2d.weight\", \"module_list.107.BatchNorm2d.bias\", \"module_list.107.BatchNorm2d.running_mean\", \"module_list.107.BatchNorm2d.running_var\", \"module_list.107.BatchNorm2d.num_batches_tracked\", \"module_list.115.Conv2d.weight\", \"module_list.115.BatchNorm2d.weight\", \"module_list.115.BatchNorm2d.bias\", \"module_list.115.BatchNorm2d.running_mean\", \"module_list.115.BatchNorm2d.running_var\", \"module_list.115.BatchNorm2d.num_batches_tracked\", \"module_list.116.Conv2d.weight\", \"module_list.116.BatchNorm2d.weight\", \"module_list.116.BatchNorm2d.bias\", \"module_list.116.BatchNorm2d.running_mean\", \"module_list.116.BatchNorm2d.running_var\", \"module_list.116.BatchNorm2d.num_batches_tracked\", \"module_list.126.Conv2d.weight\", \"module_list.126.BatchNorm2d.weight\", \"module_list.126.BatchNorm2d.bias\", \"module_list.126.BatchNorm2d.running_mean\", \"module_list.126.BatchNorm2d.running_var\", \"module_list.126.BatchNorm2d.num_batches_tracked\", \"module_list.130.Conv2d.weight\", \"module_list.130.BatchNorm2d.weight\", \"module_list.130.BatchNorm2d.bias\", \"module_list.130.BatchNorm2d.running_mean\", \"module_list.130.BatchNorm2d.running_var\", \"module_list.130.BatchNorm2d.num_batches_tracked\", \"module_list.132.Conv2d.weight\", \"module_list.132.BatchNorm2d.weight\", \"module_list.132.BatchNorm2d.bias\", \"module_list.132.BatchNorm2d.running_mean\", \"module_list.132.BatchNorm2d.running_var\", \"module_list.132.BatchNorm2d.num_batches_tracked\", \"module_list.135.Conv2d.weight\", \"module_list.135.BatchNorm2d.weight\", \"module_list.135.BatchNorm2d.bias\", \"module_list.135.BatchNorm2d.running_mean\", \"module_list.135.BatchNorm2d.running_var\", \"module_list.135.BatchNorm2d.num_batches_tracked\", \"module_list.138.Conv2d.bias\", \"module_list.143.Conv2d.weight\", \"module_list.143.BatchNorm2d.weight\", \"module_list.143.BatchNorm2d.bias\", \"module_list.143.BatchNorm2d.running_mean\", \"module_list.143.BatchNorm2d.running_var\", \"module_list.143.BatchNorm2d.num_batches_tracked\", \"module_list.146.Conv2d.weight\", \"module_list.146.BatchNorm2d.weight\", \"module_list.146.BatchNorm2d.bias\", \"module_list.146.BatchNorm2d.running_mean\", \"module_list.146.BatchNorm2d.running_var\", \"module_list.146.BatchNorm2d.num_batches_tracked\", \"module_list.149.Conv2d.bias\", \"module_list.154.Conv2d.weight\", \"module_list.154.BatchNorm2d.weight\", \"module_list.154.BatchNorm2d.bias\", \"module_list.154.BatchNorm2d.running_mean\", \"module_list.154.BatchNorm2d.running_var\", \"module_list.154.BatchNorm2d.num_batches_tracked\", \"module_list.157.Conv2d.weight\", \"module_list.157.BatchNorm2d.weight\", \"module_list.157.BatchNorm2d.bias\", \"module_list.157.BatchNorm2d.running_mean\", \"module_list.157.BatchNorm2d.running_var\", \"module_list.157.BatchNorm2d.num_batches_tracked\", \"module_list.160.Conv2d.bias\". \n\tsize mismatch for module_list.2.Conv2d.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([32, 64, 1, 1]).\n\tsize mismatch for module_list.2.BatchNorm2d.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module_list.2.BatchNorm2d.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module_list.2.BatchNorm2d.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module_list.2.BatchNorm2d.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([32]).\n\tsize mismatch for module_list.5.Conv2d.weight: copying a param with shape torch.Size([32, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for module_list.5.BatchNorm2d.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.5.BatchNorm2d.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.5.BatchNorm2d.running_mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.5.BatchNorm2d.running_var: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.6.Conv2d.weight: copying a param with shape torch.Size([64, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n\tsize mismatch for module_list.8.Conv2d.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n\tsize mismatch for module_list.10.Conv2d.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 3, 3]).\n\tsize mismatch for module_list.12.Conv2d.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for module_list.18.Conv2d.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 128, 3, 3]).\n\tsize mismatch for module_list.18.BatchNorm2d.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.18.BatchNorm2d.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.18.BatchNorm2d.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.18.BatchNorm2d.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.19.Conv2d.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for module_list.19.BatchNorm2d.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.19.BatchNorm2d.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.19.BatchNorm2d.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.19.BatchNorm2d.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.21.Conv2d.weight: copying a param with shape torch.Size([64, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for module_list.21.BatchNorm2d.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.21.BatchNorm2d.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.21.BatchNorm2d.running_mean: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.21.BatchNorm2d.running_var: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.23.Conv2d.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for module_list.25.Conv2d.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n\tsize mismatch for module_list.49.Conv2d.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).\n\tsize mismatch for module_list.49.BatchNorm2d.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.49.BatchNorm2d.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.49.BatchNorm2d.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.49.BatchNorm2d.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.50.Conv2d.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.50.BatchNorm2d.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.50.BatchNorm2d.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.50.BatchNorm2d.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.50.BatchNorm2d.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.52.Conv2d.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.52.BatchNorm2d.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.52.BatchNorm2d.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.52.BatchNorm2d.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.52.BatchNorm2d.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.54.Conv2d.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for module_list.56.Conv2d.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module_list.80.Conv2d.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 3, 3]).\n\tsize mismatch for module_list.80.BatchNorm2d.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.80.BatchNorm2d.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.80.BatchNorm2d.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.80.BatchNorm2d.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.81.Conv2d.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for module_list.81.BatchNorm2d.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.81.BatchNorm2d.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.81.BatchNorm2d.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.81.BatchNorm2d.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.83.Conv2d.weight: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for module_list.83.BatchNorm2d.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.83.BatchNorm2d.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.83.BatchNorm2d.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.83.BatchNorm2d.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.85.Conv2d.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for module_list.87.Conv2d.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n\tsize mismatch for module_list.99.Conv2d.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for module_list.102.Conv2d.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for module_list.114.Conv2d.weight: copying a param with shape torch.Size([512, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.114.BatchNorm2d.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.114.BatchNorm2d.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.114.BatchNorm2d.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.114.BatchNorm2d.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.120.Conv2d.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module_list.122.Conv2d.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module_list.123.Conv2d.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for module_list.123.BatchNorm2d.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.123.BatchNorm2d.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.123.BatchNorm2d.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.123.BatchNorm2d.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.124.Conv2d.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module_list.125.Conv2d.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for module_list.125.BatchNorm2d.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.125.BatchNorm2d.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.125.BatchNorm2d.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.125.BatchNorm2d.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.127.Conv2d.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.127.BatchNorm2d.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.127.BatchNorm2d.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.127.BatchNorm2d.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.127.BatchNorm2d.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.133.Conv2d.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for module_list.133.BatchNorm2d.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.133.BatchNorm2d.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.133.BatchNorm2d.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.133.BatchNorm2d.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.134.Conv2d.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n\tsize mismatch for module_list.136.Conv2d.weight: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n\tsize mismatch for module_list.137.Conv2d.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 128, 3, 3]).\n\tsize mismatch for module_list.137.BatchNorm2d.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.137.BatchNorm2d.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.137.BatchNorm2d.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.137.BatchNorm2d.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.138.Conv2d.weight: copying a param with shape torch.Size([18, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n\tsize mismatch for module_list.141.Conv2d.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for module_list.141.BatchNorm2d.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.141.BatchNorm2d.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.141.BatchNorm2d.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.141.BatchNorm2d.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for module_list.144.Conv2d.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.144.BatchNorm2d.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.144.BatchNorm2d.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.144.BatchNorm2d.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.144.BatchNorm2d.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.145.Conv2d.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module_list.147.Conv2d.weight: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module_list.148.Conv2d.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).\n\tsize mismatch for module_list.148.BatchNorm2d.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.148.BatchNorm2d.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.148.BatchNorm2d.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.148.BatchNorm2d.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.149.Conv2d.weight: copying a param with shape torch.Size([18, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n\tsize mismatch for module_list.152.Conv2d.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.152.BatchNorm2d.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.152.BatchNorm2d.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.152.BatchNorm2d.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.152.BatchNorm2d.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for module_list.155.Conv2d.weight: copying a param with shape torch.Size([1024, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for module_list.155.BatchNorm2d.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.155.BatchNorm2d.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.155.BatchNorm2d.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.155.BatchNorm2d.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.156.Conv2d.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n\tsize mismatch for module_list.158.Conv2d.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n\tsize mismatch for module_list.159.Conv2d.weight: copying a param with shape torch.Size([1024, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 512, 3, 3]).\n\tsize mismatch for module_list.159.BatchNorm2d.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.159.BatchNorm2d.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.159.BatchNorm2d.running_mean: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.159.BatchNorm2d.running_var: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.160.Conv2d.weight: copying a param with shape torch.Size([18, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1])."
     ]
    }
   ],
   "source": [
    "model = Darknet(cfg, imgsz).to(device).eval()\n",
    "model.load_state_dict(torch.load(weights, map_location=device)['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f699cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# Defines the new fc layer and classification layer\n",
    "# |--Linear--|--bn--|--relu--|--Linear--|\n",
    "class ClassBlock(nn.Module):\n",
    "    def __init__(self, input_dim, class_num, droprate, relu=False, bnorm=True, linear=512, return_f = False):\n",
    "        super(ClassBlock, self).__init__()\n",
    "        self.return_f = return_f\n",
    "        add_block = []\n",
    "        if linear>0:\n",
    "            add_block += [nn.Linear(input_dim, linear)]\n",
    "        else:\n",
    "            linear = input_dim\n",
    "        if bnorm:\n",
    "            add_block += [nn.BatchNorm1d(linear)]\n",
    "        if relu:\n",
    "            add_block += [nn.LeakyReLU(0.1)]\n",
    "        if droprate>0:\n",
    "            add_block += [nn.Dropout(p=droprate)]\n",
    "        add_block = nn.Sequential(*add_block)\n",
    "        \n",
    "        classifier = []\n",
    "        classifier += [nn.Linear(linear, class_num)]\n",
    "        classifier = nn.Sequential(*classifier)\n",
    "\n",
    "        self.add_block = add_block\n",
    "        self.classifier = classifier\n",
    "    def forward(self, x):\n",
    "        x = self.add_block(x)\n",
    "        if self.return_f:\n",
    "            f = x\n",
    "            x = self.classifier(x)\n",
    "            return [x,f]\n",
    "        else:\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "        \n",
    "class ft_net(nn.Module):\n",
    "    def __init__(self, class_num=100, droprate=0.5, circle=False, linear_num=512):\n",
    "        super(ft_net, self).__init__()\n",
    "        model_ft = models.resnet50(pretrained=True)\n",
    "        self.model = nn.Sequential(*list(model_ft.children())[:-1])\n",
    "        self.classifier = ClassBlock(2048, class_num, droprate, linear=linear_num, return_f = circle)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(x.size(0), x.size(1))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "reid_model = torch.load('reid_model_cosine.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b6739a",
   "metadata": {
    "id": "l1kAub6baCpD"
   },
   "source": [
    "## 預測影像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faa98fbb",
   "metadata": {
    "id": "JgM71kIdaNl_"
   },
   "outputs": [],
   "source": [
    "dataset = LoadImages(source, img_size=imgsz, auto_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bca8d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['1',\n",
    " '111',\n",
    " '112',\n",
    " '116',\n",
    " '117',\n",
    " '122',\n",
    " '123',\n",
    " '124',\n",
    " '125',\n",
    " '126',\n",
    " '132',\n",
    " '133',\n",
    " '135',\n",
    " '148',\n",
    " '15',\n",
    " '155',\n",
    " '162',\n",
    " '163',\n",
    " '166',\n",
    " '173',\n",
    " '174',\n",
    " '175',\n",
    " '181',\n",
    " '182',\n",
    " '183',\n",
    " '184',\n",
    " '185',\n",
    " '188',\n",
    " '192',\n",
    " '193',\n",
    " '197',\n",
    " '205',\n",
    " '216',\n",
    " '221',\n",
    " '222',\n",
    " '225',\n",
    " '228',\n",
    " '230',\n",
    " '231',\n",
    " '232',\n",
    " '233',\n",
    " '235',\n",
    " '265',\n",
    " '273',\n",
    " '285',\n",
    " '296',\n",
    " '3',\n",
    " '302',\n",
    " '338',\n",
    " '339',\n",
    " '341',\n",
    " '344',\n",
    " '359',\n",
    " '516',\n",
    " '517',\n",
    " '543',\n",
    " '544',\n",
    " '545',\n",
    " '55',\n",
    " '607',\n",
    " '61',\n",
    " '618',\n",
    " '619',\n",
    " '621',\n",
    " '622',\n",
    " '623',\n",
    " '624',\n",
    " '626',\n",
    " '63',\n",
    " '652',\n",
    " '653',\n",
    " '655',\n",
    " '656',\n",
    " '659',\n",
    " '660',\n",
    " '662',\n",
    " '663',\n",
    " '664',\n",
    " '705',\n",
    " '712',\n",
    " '713',\n",
    " '714',\n",
    " '734',\n",
    " '735',\n",
    " '736',\n",
    " '74',\n",
    " '75',\n",
    " '754',\n",
    " '835',\n",
    " '84',\n",
    " '857',\n",
    " '87',\n",
    " '88',\n",
    " '880',\n",
    " '881',\n",
    " '882',\n",
    " '891',\n",
    " '894',\n",
    " '90',\n",
    " '98']\n",
    "colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(class_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bb1f20e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05d01f15",
    "outputId": "d18393dc-9c08-465e-8b20-ba1ee724bfcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_01.jpg: 288x480 6\n",
      "image 2/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_02.jpg: 288x480 4\n",
      "image 3/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_03.jpg: 288x480 4\n",
      "image 4/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_04.jpg: 288x480 5\n",
      "image 5/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_05.jpg: 288x480 2\n",
      "image 6/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_06.jpg: 288x480 5\n",
      "image 7/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_07.jpg: 288x480 4\n",
      "image 8/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_08.jpg: 288x480 4\n",
      "image 9/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_09.jpg: 288x480 8\n",
      "image 10/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_10.jpg: 288x480 3\n",
      "image 11/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_11.jpg: 288x480 4\n",
      "image 12/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_12.jpg: 288x480 3\n",
      "image 13/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_13.jpg: 288x480 2\n",
      "image 14/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_14.jpg: 288x480 2\n",
      "image 15/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_15.jpg: 288x480 3\n",
      "image 16/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_16.jpg: 288x480 1\n",
      "image 17/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_17.jpg: 288x480 3\n",
      "image 18/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_18.jpg: 288x480 3\n",
      "image 19/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_19.jpg: 288x480 3\n",
      "image 20/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_20.jpg: 288x480 3\n",
      "image 21/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_21.jpg: 288x480 4\n",
      "image 22/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_22.jpg: 288x480 1\n",
      "image 23/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_23.jpg: 288x480 3\n",
      "image 24/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_24.jpg: 288x480 1\n",
      "image 25/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_25.jpg: 288x480 1\n",
      "image 26/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_26.jpg: 288x480 3\n",
      "image 27/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_27.jpg: 288x480 3\n",
      "image 28/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_28.jpg: 288x480 4\n",
      "image 29/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_29.jpg: 288x480 1\n",
      "image 30/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_30.jpg: 288x480 4\n",
      "image 31/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_31.jpg: 288x480 1\n",
      "image 32/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_32.jpg: 288x480 1\n",
      "image 33/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_33.jpg: 288x480 3\n",
      "image 34/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_34.jpg: 288x480 5\n",
      "image 35/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_35.jpg: 288x480 4\n",
      "image 36/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_36.jpg: 288x480 2\n",
      "image 37/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_37.jpg: 288x480 2\n",
      "image 38/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_38.jpg: 288x480 2\n",
      "image 39/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_39.jpg: 288x480 4\n",
      "image 40/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_40.jpg: 288x480 2\n",
      "image 41/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_41.jpg: 288x480 1\n",
      "image 42/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_42.jpg: 288x480 6\n",
      "image 43/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_43.jpg: 288x480 3\n",
      "image 44/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_44.jpg: 288x480 4\n",
      "image 45/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_45.jpg: 288x480 4\n",
      "image 46/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_46.jpg: 288x480 1\n",
      "image 47/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_47.jpg: 288x480 7\n",
      "image 48/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_48.jpg: 288x480 7\n",
      "image 49/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_49.jpg: 288x480 5\n",
      "image 50/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_50.jpg: 288x480 1\n",
      "image 51/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_51.jpg: 288x480 2\n",
      "image 52/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_52.jpg: 288x480 3\n",
      "image 53/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_53.jpg: 288x480 1\n",
      "image 54/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_54.jpg: 288x480 2\n",
      "image 55/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_55.jpg: 288x480 1\n",
      "image 56/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_56.jpg: 288x480 4\n",
      "image 57/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_57.jpg: 288x480 2\n",
      "image 58/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_58.jpg: 288x480 4\n",
      "image 59/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_59.jpg: 288x480 3\n",
      "image 60/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_60.jpg: 288x480 9\n",
      "image 61/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_61.jpg: 288x480 1\n",
      "image 62/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_62.jpg: 288x480 4\n",
      "image 63/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_63.jpg: 288x480 2\n",
      "image 64/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_64.jpg: 288x480 2\n",
      "image 65/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_65.jpg: 288x480 3\n",
      "image 66/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_66.jpg: 288x480 2\n",
      "image 67/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_67.jpg: 288x480 3\n",
      "image 68/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_68.jpg: 288x480 3\n",
      "image 69/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_69.jpg: 288x480 3\n",
      "image 70/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_70.jpg: 288x480 4\n",
      "image 71/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_71.jpg: 288x480 2\n",
      "image 72/153 /home/jovyan/person_reid/person_reid_datasets/test/c1_72.jpg: 288x480 5\n",
      "image 73/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_01.jpg: 288x480 2\n",
      "image 74/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_02.jpg: 288x480 3\n",
      "image 75/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_03.jpg: 288x480 2\n",
      "image 76/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_04.jpg: 288x480 1\n",
      "image 77/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_05.jpg: 288x480 3\n",
      "image 78/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_06.jpg: 288x480 2\n",
      "image 79/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_07.jpg: 288x480 3\n",
      "image 80/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_08.jpg: 288x480 3\n",
      "image 81/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_09.jpg: 288x480 1\n",
      "image 82/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_10.jpg: 288x480 3\n",
      "image 83/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_11.jpg: 288x480 2\n",
      "image 84/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_12.jpg: 288x480 3\n",
      "image 85/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_13.jpg: 288x480 4\n",
      "image 86/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_14.jpg: 288x480 1\n",
      "image 87/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_15.jpg: 288x480 1\n",
      "image 88/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_16.jpg: 288x480 2\n",
      "image 89/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_17.jpg: 288x480 4\n",
      "image 90/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_18.jpg: 288x480 3\n",
      "image 91/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_19.jpg: 288x480 1\n",
      "image 92/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_20.jpg: 288x480 1\n",
      "image 93/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_21.jpg: 288x480 2\n",
      "image 94/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_22.jpg: 288x480 2\n",
      "image 95/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_23.jpg: 288x480 2\n",
      "image 96/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_24.jpg: 288x480 3\n",
      "image 97/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_25.jpg: 288x480 3\n",
      "image 98/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_26.jpg: 288x480 1\n",
      "image 99/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_27.jpg: 288x480 2\n",
      "image 100/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_28.jpg: 288x480 2\n",
      "image 101/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_29.jpg: 288x480 1\n",
      "image 102/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_30.jpg: 288x480 3\n",
      "image 103/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_31.jpg: 288x480 4\n",
      "image 104/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_32.jpg: 288x480 2\n",
      "image 105/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_33.jpg: 288x480 1\n",
      "image 106/153 /home/jovyan/person_reid/person_reid_datasets/test/c2_34.jpg: 288x480 4\n",
      "image 107/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_01.jpg: 288x480 3\n",
      "image 108/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_02.jpg: 288x480 4\n",
      "image 109/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_03.jpg: 288x480 1\n",
      "image 110/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_04.jpg: 288x480 2\n",
      "image 111/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_05.jpg: 288x480 3\n",
      "image 112/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_06.jpg: 288x480 1\n",
      "image 113/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_07.jpg: 288x480 4\n",
      "image 114/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_08.jpg: 288x480 3\n",
      "image 115/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_09.jpg: 288x480 3\n",
      "image 116/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_10.jpg: 288x480 3\n",
      "image 117/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_11.jpg: 288x480 2\n",
      "image 118/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_12.jpg: 288x480 5\n",
      "image 119/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_13.jpg: 288x480 4\n",
      "image 120/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_14.jpg: 288x480 2\n",
      "image 121/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_15.jpg: 288x480 2\n",
      "image 122/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_16.jpg: 288x480 4\n",
      "image 123/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_17.jpg: 288x480 5\n",
      "image 124/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_18.jpg: 288x480 1\n",
      "image 125/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_19.jpg: 288x480 3\n",
      "image 126/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_20.jpg: 288x480 2\n",
      "image 127/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_21.jpg: 288x480 8\n",
      "image 128/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_22.jpg: 288x480 2\n",
      "image 129/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_23.jpg: 288x480 7\n",
      "image 130/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_24.jpg: 288x480 2\n",
      "image 131/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_25.jpg: 288x480 3\n",
      "image 132/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_26.jpg: 288x480 3\n",
      "image 133/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_27.jpg: 288x480 4\n",
      "image 134/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_28.jpg: 288x480 3\n",
      "image 135/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_29.jpg: 288x480 1\n",
      "image 136/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_30.jpg: 288x480 1\n",
      "image 137/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_31.jpg: 288x480 4\n",
      "image 138/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_32.jpg: 288x480 3\n",
      "image 139/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_33.jpg: 288x480 2\n",
      "image 140/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_34.jpg: 288x480 3\n",
      "image 141/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_35.jpg: 288x480 2\n",
      "image 142/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_36.jpg: 288x480 2\n",
      "image 143/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_37.jpg: 288x480 2\n",
      "image 144/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_38.jpg: 288x480 2\n",
      "image 145/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_39.jpg: 288x480 4\n",
      "image 146/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_40.jpg: 288x480 3\n",
      "image 147/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_41.jpg: 288x480 3\n",
      "image 148/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_42.jpg: 288x480 4\n",
      "image 149/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_43.jpg: 288x480 5\n",
      "image 150/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_44.jpg: 288x480 4\n",
      "image 151/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_45.jpg: 288x480 3\n",
      "image 152/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_46.jpg: 288x480 2\n",
      "image 153/153 /home/jovyan/person_reid/person_reid_datasets/test/c3_47.jpg: 288x480 3\n",
      "Results saved to inference/output\n",
      "Done. (12.716s)\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv(sub)\n",
    "submission = submission.drop([0])\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    t0 = time.time()\n",
    "    img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
    "    _ = model(img) # run once\n",
    "    for path, img, im0s, vid_cap in dataset:\n",
    "        basename = os.path.basename(path)\n",
    "        basename_no_ext = os.path.splitext(basename)[0]\n",
    "        \n",
    "        h, w, _ = im0s.shape\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "        # Inference\n",
    "        t1 = time_synchronized()\n",
    "        pred = model(img)[0]\n",
    "\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression(pred, conf_thres, iou_thres)\n",
    "        t2 = time_synchronized()\n",
    "\n",
    "        # Process detections\n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            p, s, im0 = path, '', im0s\n",
    "            save_path = str(Path(out) / Path(p).name)\n",
    "            s += '%gx%g ' % img.shape[2:]  # print string\n",
    "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "            if det is not None and len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "                # Print results\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    s += '%g' % n  # add to string\n",
    "\n",
    "                # Write results\n",
    "                for *xyxy, conf, cls in det:\n",
    "                    crop_img = im0[int(xyxy[1]):int(xyxy[3]), int(xyxy[0]):int(xyxy[2])]\n",
    "                    crop_img_resize = cv2.resize(crop_img[:,:,::-1], (192, 384))\n",
    "                    crop_img_resize = ((crop_img_resize/255 - (0.485, 0.456, 0.406)) / (0.229, 0.224, 0.225)).astype('float32') # 0 - 255 to 0.0 - 1.0\n",
    "                    crop_img_resize = crop_img_resize.transpose((2, 0, 1))\n",
    "                    crop_img_resize = np.expand_dims(crop_img_resize, 0)\n",
    "                    crop_img_resize = torch.from_numpy(crop_img_resize).to(device)\n",
    "                    reid_model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        outputs, _ = reid_model(crop_img_resize)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                    reid = class_names[preds[0]]\n",
    "                    submission.loc[len(submission)] = [basename_no_ext,\n",
    "                                                       reid,\n",
    "                                                       float(conf.cpu()),\n",
    "                                                       int(xyxy[0].cpu())/w,\n",
    "                                                       int(xyxy[1].cpu())/h,\n",
    "                                                       int(xyxy[2].cpu())/w,\n",
    "                                                       int(xyxy[3].cpu())/h]\n",
    "            print(s)\n",
    "#                     plot_one_box(xyxy, im0, label=reid, color=colors[class_names.index(reid)], line_thickness=1)\n",
    "#             cv2.imwrite(save_path, im0)\n",
    "    print('Results saved to %s' % Path(out))\n",
    "    print('Done. (%.3fs)' % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c58dfde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_cosine.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2abbae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:2963: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "from mean_average_precision.detection_map import DetectionMAP\n",
    "from cryptography.fernet import Fernet\n",
    "encrypt_key = b'rVbMiUCK8WHS1nJ79_TcBz7UpEWrtoVY1V47UTzaBA0=' \n",
    "f = Fernet(encrypt_key)\n",
    "token2 = pd.read_csv('answer_encrypted.csv') \n",
    "token3 = token2.applymap(lambda x: bytes(x[2:-1],'utf-8'))\n",
    "token4 = token3.applymap(lambda x: f.decrypt(x))\n",
    "df_decrp = token4.applymap(lambda x: x.decode('utf-8'))\n",
    "answer = df_decrp.loc[:434]\n",
    "answer[['reid']] = answer[['reid']].apply(lambda x: x.astype(int)) # preprocess\n",
    "answer[['confidence', 'left', 'top', 'right', 'bottom']] = answer[['confidence', 'left', 'top', 'right', 'bottom']].apply(lambda x: x.astype(float)) # preprocess\n",
    "submission = pd.read_csv('submission_cosine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "160e580c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "filenames = np.unique(answer['filename'])\n",
    "class_names = [  1,   3,  15,  55,  61,  63,  74,  75,  84,  87,  88,  90,  98,\n",
    "       111, 112, 116, 117, 122, 123, 124, 125, 126, 132, 133, 135, 148,\n",
    "       155, 162, 163, 166, 173, 174, 175, 181, 182, 183, 184, 185, 188,\n",
    "       192, 193, 197, 205, 216, 221, 222, 225, 228, 230, 231, 232, 233,\n",
    "       235, 265, 273, 285, 296, 302, 338, 339, 341, 344, 359, 516, 517,\n",
    "       543, 544, 545, 607, 618, 619, 621, 622, 623, 624, 626, 652, 653,\n",
    "       655, 656, 659, 660, 662, 663, 664, 705, 712, 713, 714, 734, 735,\n",
    "       736, 754, 835, 857, 880, 881, 882, 891, 894]\n",
    "cls_name_dict = {k:v for v, k in enumerate(class_names)}\n",
    "submission['reid'] = submission['reid'].map(cls_name_dict)\n",
    "answer['reid'] = answer['reid'].map(cls_name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc07f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for file in filenames:\n",
    "    sub = submission[submission['filename']==file]\n",
    "    ans = answer[answer['filename']==file]\n",
    "    pred_bb = sub[['left', 'top', 'right', 'bottom']].values\n",
    "    pred_cls = sub['reid'].values\n",
    "    pred_conf = sub['confidence'].values\n",
    "    gt_bb = ans[['left', 'top', 'right', 'bottom']].values\n",
    "    gt_cls = ans['reid'].values\n",
    "    frames.append((pred_bb, pred_cls, pred_conf, gt_bb, gt_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bdfbe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP@.5: 0.695538270999341\n",
      "mAP@.55: 0.6940967125577825\n",
      "mAP@.6: 0.6898065339863539\n",
      "mAP@.65: 0.6887861258230886\n",
      "mAP@.7: 0.6641967451475763\n",
      "mAP@.75: 0.6421488624957163\n",
      "mAP@.8: 0.5590924501469767\n",
      "mAP@.85: 0.4464772405098747\n",
      "mAP@.9: 0.36344621915888536\n",
      "mAP@.95: 0.33398593073593075\n",
      "mAP@.5:.95: 0.5777575091561525\n"
     ]
    }
   ],
   "source": [
    "n_class = len(class_names)\n",
    "\n",
    "thresh = [0.5 , 0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95]\n",
    "mAP_all = []\n",
    "for thre in thresh:\n",
    "    mAP = DetectionMAP(n_class, overlap_threshold=thre)\n",
    "    for i, frame in enumerate(frames):\n",
    "    #     print(\"Evaluate frame {}\".format(i))\n",
    "    #     show_frame(*frame)\n",
    "        mAP.evaluate(*frame)\n",
    "    print('mAP@' + str(thre)[1:] + f': {mAP.compute_mAP()}')\n",
    "    mAP_all.append(mAP.compute_mAP())\n",
    "\n",
    "print(f'mAP@.5:.95: {np.average(mAP_all)}')\n",
    "# print('mAP:', mAP.compute_mAP())\n",
    "# mAP.plot(class_names=class_names, figsize=30)\n",
    "# plt.show()\n",
    "#plt.savefig(\"pr_curve_example.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e57ad8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "YOLOv4_detect.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
