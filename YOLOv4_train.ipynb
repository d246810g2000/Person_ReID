{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b157ac43",
   "metadata": {
    "id": "ttRwgqBzYQKE"
   },
   "source": [
    "# YOLOv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "917e07e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'PyTorch_YOLOv4'...\n",
      "remote: Enumerating objects: 817, done.\u001b[K\n",
      "remote: Counting objects: 100% (169/169), done.\u001b[K\n",
      "remote: Compressing objects: 100% (123/123), done.\u001b[K\n",
      "remote: Total 817 (delta 68), reused 131 (delta 38), pack-reused 648\u001b[K\n",
      "Receiving objects: 100% (817/817), 34.64 MiB | 12.10 MiB/s, done.\n",
      "Resolving deltas: 100% (421/421), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "repo = 'PyTorch_YOLOv4'\n",
    "\n",
    "# 檢查是否已有 PyTorch_YOLOv4 的 repo, 若有則刪除\n",
    "if os.path.exists(repo):\n",
    "    shutil.rmtree(repo)  # delete output folder\n",
    "!git clone https://github.com/d246810g2000/PyTorch_YOLOv4.git\n",
    "    \n",
    "sys.path.append(repo)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69eddcc",
   "metadata": {
    "id": "XQXgxe34fucu"
   },
   "source": [
    "### 安裝所需套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9733cc67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i6njqfDCfucx",
    "outputId": "fa3e290b-4745-40ac-c360-13cea7793402"
   },
   "outputs": [],
   "source": [
    "!pip install wandb pycocotools -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb40956",
   "metadata": {
    "id": "1oaNWg0UgC_x"
   },
   "source": [
    "### 資料集轉換格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c6977bd",
   "metadata": {
    "id": "lynBZqZVf0wH"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def getImagesInDir(dir_path):\n",
    "    img_formats = ['bmp', 'jpg', 'jpeg', 'png', 'tif', 'tiff', 'dng']  # acceptable image suffixes\n",
    "    image_list = []\n",
    "    for img_format in img_formats:\n",
    "        for filename in glob.glob(dir_path + f'/*.{img_format}'):\n",
    "            image_list.append(filename)\n",
    "\n",
    "    return image_list\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1./(size[0])\n",
    "    dh = 1./(size[1])\n",
    "    x = (box[0] + box[1])/2.0 - 1\n",
    "    y = (box[2] + box[3])/2.0 - 1\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x,y,w,h)\n",
    "\n",
    "def convert_annotation(img_path, ann_dir, output_image_path, output_label_path):\n",
    "    basename = os.path.basename(img_path)\n",
    "    basename_no_ext = os.path.splitext(basename)[0]\n",
    "    \n",
    "    #copy image\n",
    "    shutil.copy(img_path, os.path.join(output_image_path, basename))\n",
    "\n",
    "    in_file = open(ann_dir + '/' + basename_no_ext + '.xml')\n",
    "    out_file = open(output_label_path + basename_no_ext + '.txt', 'w')\n",
    "    tree = ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    w = int(size.find('width').text)\n",
    "    h = int(size.find('height').text)\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = obj.find('difficult').text\n",
    "        cls = obj.find('name').text\n",
    "        if cls not in classes or int(difficult)==1:\n",
    "            continue\n",
    "        cls_id = classes.index(cls)\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
    "        bb = convert((w,h), b)\n",
    "        out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
    "\n",
    "name = 'pedestrian'\n",
    "classes = ['pedestrian']\n",
    "train_test_split_rate = 0.2\n",
    "\n",
    "img_dir = 'person_reid_datasets/train/JPEGImages/'\n",
    "ann_dir = 'person_reid_datasets/train/Annotations/'\n",
    "image_paths = getImagesInDir(img_dir)\n",
    "random.seed(2022)\n",
    "random.shuffle(image_paths)\n",
    "\n",
    "train_image_path = f'PyTorch_YOLOv4/datasets/{name}/train/images/'\n",
    "train_label_path = f'PyTorch_YOLOv4/datasets/{name}/train/labels/'\n",
    "valid_image_path = f'PyTorch_YOLOv4/datasets/{name}/valid/images/'\n",
    "valid_label_path = f'PyTorch_YOLOv4/datasets/{name}/valid/labels/'\n",
    "\n",
    "if not os.path.exists(train_image_path):\n",
    "    os.makedirs(train_image_path)\n",
    "if not os.path.exists(train_label_path):\n",
    "    os.makedirs(train_label_path)\n",
    "if not os.path.exists(valid_image_path):\n",
    "    os.makedirs(valid_image_path)\n",
    "if not os.path.exists(valid_label_path):\n",
    "    os.makedirs(valid_label_path)\n",
    "\n",
    "train_test_split = len(image_paths)*train_test_split_rate\n",
    "\n",
    "for i, img_path in enumerate(image_paths):\n",
    "    if i >= train_test_split:\n",
    "        # train\n",
    "        convert_annotation(img_path, ann_dir, train_image_path, train_label_path)\n",
    "    else:\n",
    "        # valid\n",
    "        convert_annotation(img_path, ann_dir, valid_image_path, valid_label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa561dcc",
   "metadata": {
    "id": "rFYHjgQqgI6L"
   },
   "source": [
    "### 創建 yaml 和 cfg 檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c51da0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "huluxCAZgYoJ",
    "outputId": "13ce6c13-d76f-444f-da41-ff4b29c134bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: PyTorch_YOLOv4/datasets/pedestrian/train/images\n",
      "val: PyTorch_YOLOv4/datasets/pedestrian/valid/images\n",
      "\n",
      "nc: 1\n",
      "names: [pedestrian]\n"
     ]
    }
   ],
   "source": [
    "!echo -e 'train: PyTorch_YOLOv4/datasets/pedestrian/train/images\\nval: PyTorch_YOLOv4/datasets/pedestrian/valid/images\\n\\nnc: 1\\nnames: [pedestrian]' > PyTorch_YOLOv4/data/pedestrian.yaml\n",
    "!head PyTorch_YOLOv4/data/pedestrian.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5900605",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whvB-2LdgiX9",
    "outputId": "b98cdb6b-ea1a-4d62-b94b-12f5161f22c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filters=255\n",
      "classes=80\n",
      "filters=255\n",
      "classes=80\n",
      "filters=255\n",
      "classes=80\n"
     ]
    }
   ],
   "source": [
    "!cp PyTorch_YOLOv4/cfg/yolov4.cfg PyTorch_YOLOv4/cfg/yolov4_pedestrian.cfg\n",
    "!sed -n -e 959p -e 966p -e 1046p -e 1053p -e 1133p -e 1140p PyTorch_YOLOv4/cfg/yolov4_pedestrian.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58ad1caa",
   "metadata": {
    "id": "02j_JfwPgiX-"
   },
   "outputs": [],
   "source": [
    "!sed -i '959s/255/18/' PyTorch_YOLOv4/cfg/yolov4_pedestrian.cfg # (classes + 5)x3\n",
    "!sed -i '966s/80/1/' PyTorch_YOLOv4/cfg/yolov4_pedestrian.cfg\n",
    "!sed -i '1046s/255/18/' PyTorch_YOLOv4/cfg/yolov4_pedestrian.cfg # (classes + 5)x3\n",
    "!sed -i '1053s/80/1/' PyTorch_YOLOv4/cfg/yolov4_pedestrian.cfg\n",
    "!sed -i '1133s/255/18/' PyTorch_YOLOv4/cfg/yolov4_pedestrian.cfg # (classes + 5)x3\n",
    "!sed -i '1140s/80/1/' PyTorch_YOLOv4/cfg/yolov4_pedestrian.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "379bcf25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "auJtjmo6giX_",
    "outputId": "95e67710-27f8-4a5b-c970-6cacbb43e6c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filters=18\n",
      "classes=1\n",
      "filters=18\n",
      "classes=1\n",
      "filters=18\n",
      "classes=1\n"
     ]
    }
   ],
   "source": [
    "!sed -n -e 959p -e 966p -e 1046p -e 1053p -e 1133p -e 1140p PyTorch_YOLOv4/cfg/yolov4_pedestrian.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090ef2e",
   "metadata": {
    "id": "yU36gtbLhvLe"
   },
   "source": [
    "### 使用 wandb 記錄訓練過程\n",
    "- 先進入官網登入：https://wandb.ai/site \n",
    "- 右上方頭像 -> settings -> 複製 API keys -> 填入下方輸入處"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36aa7cb1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "BQJSuQLfhvLg",
    "outputId": "b4ad6977-348e-427d-9375-8f0396f7cfdb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33md246810g2000\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/Person_ReID/wandb/run-20220419_170421-14zve55r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/d246810g2000/Person_ReID/runs/14zve55r\" target=\"_blank\">olive-thunder-1</a></strong> to <a href=\"https://wandb.ai/d246810g2000/Person_ReID\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "# Logging\n",
    "id = wandb.util.generate_id()\n",
    "wandb_run = wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d67c616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21s20fv5'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972b11a",
   "metadata": {
    "id": "sII5gT_YjBSd"
   },
   "source": [
    "### 開始訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b06a7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSuDjPdEl65F",
    "outputId": "45825ee2-7687-4fb3-86cf-28f03266880d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: built-in: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# command line training\n",
    "!python PyTorch_YOLOv4/train.py --device 0 --batch-size 4 --img-size 416 --data PyTorch_YOLOv4/data/pedestrian.yaml --cfg PyTorch_YOLOv4/cfg/yolov4_pedestrian.cfg --weights '' --name $id --epochs 300 --multi-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d6fa95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "YOLOv4_train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
